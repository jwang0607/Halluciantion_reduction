{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTyk1uTI_X7t"
      },
      "outputs": [],
      "source": [
        "#Clone the DRIVELM\n",
        "!git clone https://github.com/OpenDriveLab/DriveLM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb1g7k0bigrg"
      },
      "outputs": [],
      "source": [
        "#Install conda\n",
        "!curl -O https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SMFAm42iiaM"
      },
      "outputs": [],
      "source": [
        "!bash Anaconda3-2023.09-0-Linux-x86_64.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwjXZM15v3Uc"
      },
      "outputs": [],
      "source": [
        "# Start the conda\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/anaconda3/bin:{os.environ['PATH']}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFCMThMn0FP6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "13O5l9Sgi6tJ"
      },
      "outputs": [],
      "source": [
        "# Create the environment\n",
        "!conda create -n llama_adapter_v2 python=3.8 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZFK5yryJlD5"
      },
      "outputs": [],
      "source": [
        "# prompt: Active llama_adapter_v2  environment\n",
        "!conda run -n llama_adapter_v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw62a-lm-LYk"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8bh8PBQTozs"
      },
      "outputs": [],
      "source": [
        "%cd DriveLM/challenge/llama_adapter_v2_multimodal7b/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RsK71wYT3AS"
      },
      "outputs": [],
      "source": [
        "# Replace the dataset for images\n",
        "!rm -rf nuscenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_84NUBK3TyXK"
      },
      "outputs": [],
      "source": [
        "#clone samples from Nuscenes in Hugging face\n",
        "!git clone https://huggingface.co/Jue97/nuscenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txtsuYvIT5PB"
      },
      "outputs": [],
      "source": [
        "# prompt: unzip sample file\n",
        "# Import the necessary libraries\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = \"/content/DriveLM/challenge/llama_adapter_v2_multimodal7b/data/nuscenes/samples.zip\"\n",
        "\n",
        "# Specify the directory to extract the files to\n",
        "extract_dir = \"/content/DriveLM/challenge/llama_adapter_v2_multimodal7b/data/nuscenes\"\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the files to the specified directory\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aOVtjR26M5lt"
      },
      "outputs": [],
      "source": [
        "# Follow the instructions in DrivelM to install the required files and change the format of evaluation inputs.\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GaleH42cM9IQ"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate\n",
        "!pip install timm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hog3djsxOb5o"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "36R5Lx9rGqto"
      },
      "outputs": [],
      "source": [
        "!python convert2llama.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UtmSPzRU6D_"
      },
      "outputs": [],
      "source": [
        "%cd llama_adapter_v2_multimodal7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U0gCvcHIJNUo"
      },
      "outputs": [],
      "source": [
        "# This will get the output.json file\n",
        "# The --num_gpus 1 is the number of GPUs used.\n",
        "!python demo.py --data ../test_gpt.json  --output ../output.json --batch_size 4 --num_gpus 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "06L8b32xAgS1"
      },
      "outputs": [],
      "source": [
        "!sudo apt install libxml-parser-perl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hRF4QIbSBwKR"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/bckim92/language-evaluation.git\n",
        "!python -c \"import language_evaluation; language_evaluation.download('coco')\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6c7L1ZkCdw8"
      },
      "outputs": [],
      "source": [
        "# prompt: go to challenge folder\n",
        "%cd DriveLM/challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7oPYIZYnCgl6"
      },
      "outputs": [],
      "source": [
        "# Need to use the output.json and test_gpt.json\n",
        "!python evaluation.py --root_path1 ./output.json --root_path2 ./test_gpt.json --num_rounds 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEZ3u9y05Cx7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QKkG_xkjG9s"
      },
      "outputs": [],
      "source": [
        "result1 = [0.31539045860172205, 0.2773904586017221, 0.3043904586017221, 0.33239045860172206, 0.2953904586017221, 0.3893904586017221, 0.37739045860172205, 0.2923904586017221, 0.28239045860172207, 0.37939045860172205]\n",
        "result2 = [0.15539045860172207, 0.28539045860172213, 0.4463904586017221, 0.2463904586017221, 0.35839045860172203, 0.2553904586017221, 0.37239045860172204, 0.2933904586017221, 0.33539045860172206, 0.349390458601722]\n",
        "result3 = [0.25839045860172205, 0.2613904586017221, 0.34039045860172207, 0.33939045860172207, 0.2303904586017221, 0.3703904586017221, 0.3923904586017221, 0.2133904586017221, 0.2473904586017221, 0.353390458601722]\n",
        "result4 = [0.36239045860172203, 0.3823904586017221, 0.26239045860172205, 0.3853904586017221, 0.32539045860172205, 0.3023904586017221, 0.39039045860172206, 0.2633904586017221, 0.3923904586017221, 0.347390458601722]\n",
        "result5 = [0.36839045860172204, 0.30939045860172204, 0.31539045860172205, 0.335390458601722, 0.32239045860172205, 0.3753904586017221, 0.28039045860172207, 0.27939045860172207, 0.27539045860172207, 0.36339045860172203]\n",
        "result6 = [0.3053904586017221, 0.31839045860172205, 0.3503904586017221, 0.348390458601722, 0.30739045860172204, 0.33039045860172206, 0.35939045860172203, 0.3693904586017221, 0.340390458601722, 0.35939045860172203]\n",
        "result7 = [0.347390458601722, 0.20739045860172212, 0.26939045860172206, 0.4203904586017221, 0.2863904586017221, 0.25939045860172205, 0.347390458601722, 0.3113904586017221, 0.12339045860172206, 0.2073904586017221]\n",
        "result8 = [0.27739045860172207, 0.32539045860172205, 0.22939045860172208, 0.37139045860172204, 0.36539045860172203, 0.27339045860172206, 0.3053904586017221, 0.2563904586017221, 0.3873904586017221, 0.40039045860172207]\n",
        "result9 = [0.2953904586017221, 0.2373904586017221, 0.343390458601722, 0.2883904586017221, 0.3023904586017221, 0.1783904586017221, 0.3923904586017221, 0.28039045860172207, 0.22139045860172207, 0.2583904586017221]\n",
        "result10 = [0.3103904586017221, 0.31539045860172205, 0.3013904586017221, 0.3623904586017221, 0.2963904586017221, 0.27039045860172206, 0.34039045860172207, 0.2753904586017221, 0.2673904586017221, 0.36339045860172203]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py1IWYRCkFoY"
      },
      "outputs": [],
      "source": [
        "# Given lists\n",
        "result1 = [0.31539045860172205, 0.2773904586017221, 0.3043904586017221, 0.33239045860172206, 0.2953904586017221, 0.3893904586017221, 0.37739045860172205, 0.2923904586017221, 0.28239045860172207, 0.37939045860172205]\n",
        "result2 = [0.15539045860172207, 0.28539045860172213, 0.4463904586017221, 0.2463904586017221, 0.35839045860172203, 0.2553904586017221, 0.37239045860172204, 0.2933904586017221, 0.33539045860172206, 0.349390458601722]\n",
        "result3 = [0.25839045860172205, 0.2613904586017221, 0.34039045860172207, 0.33939045860172207, 0.2303904586017221, 0.3703904586017221, 0.3923904586017221, 0.2133904586017221, 0.2473904586017221, 0.353390458601722]\n",
        "result4 = [0.36239045860172203, 0.3823904586017221, 0.26239045860172205, 0.3853904586017221, 0.32539045860172205, 0.3023904586017221, 0.39039045860172206, 0.2633904586017221, 0.3923904586017221, 0.347390458601722]\n",
        "result5 = [0.36839045860172204, 0.30939045860172204, 0.31539045860172205, 0.335390458601722, 0.32239045860172205, 0.3753904586017221, 0.28039045860172207, 0.27939045860172207, 0.27539045860172207, 0.36339045860172203]\n",
        "result6 = [0.3053904586017221, 0.31839045860172205, 0.3503904586017221, 0.348390458601722, 0.30739045860172204, 0.33039045860172206, 0.35939045860172203, 0.3693904586017221, 0.340390458601722, 0.35939045860172203]\n",
        "result7 = [0.347390458601722, 0.20739045860172212, 0.26939045860172206, 0.4203904586017221, 0.2863904586017221, 0.25939045860172205, 0.347390458601722, 0.3113904586017221, 0.12339045860172206, 0.2073904586017221]\n",
        "result8 = [0.27739045860172207, 0.32539045860172205, 0.22939045860172208, 0.37139045860172204, 0.36539045860172203, 0.27339045860172206, 0.3053904586017221, 0.2563904586017221, 0.3873904586017221, 0.40039045860172207]\n",
        "result9 = [0.2953904586017221, 0.2373904586017221, 0.343390458601722, 0.2883904586017221, 0.3023904586017221, 0.1783904586017221, 0.3923904586017221, 0.28039045860172207, 0.22139045860172207, 0.2583904586017221]\n",
        "result10 = [0.3103904586017221, 0.31539045860172205, 0.3013904586017221, 0.3623904586017221, 0.2963904586017221, 0.27039045860172206, 0.34039045860172207, 0.2753904586017221, 0.2673904586017221, 0.36339045860172203]\n",
        "\n",
        "combined_list = []\n",
        "for i in range(10):\n",
        "    average = (result1[i] + result2[i] + result3[i] + result4[i] + result5[i] +\n",
        "               result6[i] + result7[i] + result8[i] + result9[i] + result10[i]) / 10\n",
        "    combined_list.append(average)\n",
        "\n",
        "print(combined_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEn5DJAVliGG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Data\n",
        "combined_list = [\n",
        "    0.2994704586017221, 0.2921404586017221, 0.3204304586017221,\n",
        "    0.3425804586017221, 0.3112804586017221, 0.3108204586017221,\n",
        "    0.3559304586017221, 0.2832104586017221, 0.2881504586017221,\n",
        "    0.3358204586017221\n",
        "]\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), combined_list, marker='o')\n",
        "# Labels and title\n",
        "plt.title('Combined List Values per Round')\n",
        "plt.xlabel('Round')\n",
        "plt.ylabel('Value')\n",
        "plt.ylim(0, 0.5)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}